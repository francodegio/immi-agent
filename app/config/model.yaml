llm:
  download_args:
    size: TheBloke/Llama-2-13B-chat-GGUF
    name: llama-2-13b-chat.Q5_K_S.gguf
  runtime_args:
    model_path: ./llm.gguf
    n_gpu_layers: 60
    n_batch: 512
    n_ctx: 2048
    verbose: True

vectorstore:
  model:
    model_name: sentence-transformers/all-mpnet-base-v2
    model_kwargs: 
      device: cuda
  text_splitter:
    chunk_size: 2048
    overlap: 20
