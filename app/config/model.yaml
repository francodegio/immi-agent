llm:
  download_args:
    size: TheBloke/Llama-2-13B-chat-GGUF
    name: llama-2-13b-chat.Q5_K_S.gguf
  runtime_args:
    model_path: ./llm.gguf
    n_gpu_layers: 60
    n_batch: 512
    n_ctx: 3072
    verbose: True
    streaming: False

vectorstore:
  model:
    model_name: sentence-transformers/all-mpnet-base-v2
    model_kwargs: 
      device: cuda
  text_splitter:
    chunk_size: 2048
    chunk_overlap: 20

chain:
  prompts:
    CONDENSE_QUESTION_PROMPT: ./config/condense_question_prompt.txt
    ANSWER_PROMPT: ./config/answer_prompt.txt
  similarity:
    score_threshold: 0.5
    k: 2